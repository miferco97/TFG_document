\chapter{\tb{Estado del arte}}

Las teoría clásica de control empleada para estabilizar un cuadricóptero requiere un fino ajuste de los parámetros del modelo. Los últimos avances en aprendizaje automático han permitido que se desarrollen nuevos algoritmos de control empleando técnicas de aprendizaje por refuerzo y redes neuronales.

 En 2004, HJ Kim et al. \cite{kim2004autonomous} emplearon algoritmos de \textit{reinforcement learing} para estabilizar (\textit{hoover}) un helicóptero y conseguir realizar maniobras acrobáticas.En 2006 Andrew Y. et al \cite{ng2006autonomous} siguieron con esta investigación consiguiendo que el helicóptero se estabilizara al revés (\textit{inverted hoover}). En 2010 Travis Dierks et al. \cite{dierks2010output} desarrollaron un controlador no lineal, basado en redes neuronales, para estabilizar un cuadricóptero y seguir trayectorias.
 
 Unos años después, en 2017 Jemin Hwangbo et al. \cite{hwangbo2017control} desarrollaron un método para controlar un quadricóptero con una red neuronal usando técnicas de \textit{reinforcement learning}. En 2018 William Koch et al. \cite{koch2019reinforcement} desarrollaron un entorno de simulación, GYMFC, para el desarrollo de sistemas de control empleando RL.

